# FusionAI Companion Environment Configuration
# Copy this file to .env and fill in your actual values

# ==============================================
# LLM Provider API Keys
# ==============================================

# OpenAI
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic Claude
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Google Gemini
GEMINI_API_KEY=your_gemini_api_key_here

# OpenRouter (Multi-model access)
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Groq
GROQ_API_KEY=your_groq_api_key_here

# ==============================================
# Local AI Configuration
# ==============================================

# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODELS=qwen:14b,mistral:7b,deepseek:6.7b,llama2:7b

# Local AI Base URL (if using different setup)
LOCAL_AI_BASE_URL=http://localhost:8080

# ==============================================
# Database Configuration
# ==============================================

# Supabase Configuration
SUPABASE_URL=your_supabase_url_here
SUPABASE_ANON_KEY=your_supabase_anon_key_here
SUPABASE_SERVICE_ROLE_KEY=your_supabase_service_role_key_here

# PostgreSQL (if using direct connection)
DATABASE_URL=postgresql://username:password@localhost:5432/fusionai

# Neo4j Configuration (Knowledge Graph)
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_neo4j_password_here

# ==============================================
# Vector Database
# ==============================================

# pgvector (if using separate vector db)
VECTOR_DB_URL=postgresql://username:password@localhost:5432/vectordb

# Qdrant (alternative vector database)
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=your_qdrant_api_key_here

# ==============================================
# Search and Crawling
# ==============================================

# SearXNG Configuration
SEARXNG_URL=http://localhost:8080

# Crawl4AI Configuration
CRAWL4AI_API_URL=http://localhost:8000

# ==============================================
# Workflow Automation
# ==============================================

# n8n Configuration
N8N_HOST=localhost
N8N_PORT=5678
N8N_PROTOCOL=http
N8N_BASIC_AUTH_ACTIVE=false
N8N_BASIC_AUTH_USER=admin
N8N_BASIC_AUTH_PASSWORD=your_n8n_password_here

# ==============================================
# Speech and Audio
# ==============================================

# Whisper Configuration (STT)
WHISPER_MODEL=base
WHISPER_LANGUAGE=hu

# TTS Configuration
TTS_PROVIDER=chatterbox
TTS_VOICE=hu-female-1
TTS_SPEED=1.0

# ==============================================
# VTuber and Streaming
# ==============================================

# SnekStudio Configuration
SNEKSTUDIO_MODEL_PATH=./vtuber/models/default.vrm
SNEKSTUDIO_PORT=8090

# OBS Studio Integration
OBS_WEBSOCKET_URL=ws://localhost:4455
OBS_WEBSOCKET_PASSWORD=your_obs_password_here

# ==============================================
# Monitoring and Analytics
# ==============================================

# Langfuse Configuration
LANGFUSE_PUBLIC_KEY=your_langfuse_public_key_here
LANGFUSE_SECRET_KEY=your_langfuse_secret_key_here
LANGFUSE_HOST=http://localhost:3000

# Custom Analytics
ANALYTICS_ENABLED=true
ANALYTICS_ENDPOINT=http://localhost:9000

# ==============================================
# Security and Access
# ==============================================

# JWT Secret for authentication
JWT_SECRET=your_jwt_secret_here

# Session Configuration
SESSION_SECRET=your_session_secret_here

# CORS Configuration
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8080

# ==============================================
# Development Configuration
# ==============================================

# Environment
NODE_ENV=development
DEBUG=true
LOG_LEVEL=info

# Hot Reload
HOT_RELOAD=true

# Port Configuration
API_PORT=3001
WEB_PORT=3000
WEBSOCKET_PORT=3002

# ==============================================
# Docker Configuration
# ==============================================

# Docker Compose Profile
COMPOSE_PROFILES=full

# Volume Paths
DATA_PATH=./data
MODELS_PATH=./models
LOGS_PATH=./logs

# ==============================================
# Resource Limits
# ==============================================

# Memory Limits (for Docker containers)
OLLAMA_MEMORY_LIMIT=8g
NEO4J_MEMORY_LIMIT=2g
SUPABASE_MEMORY_LIMIT=4g

# GPU Configuration
CUDA_VISIBLE_DEVICES=0
GPU_MEMORY_FRACTION=0.8
